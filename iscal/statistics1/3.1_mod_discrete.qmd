---
title: "Probabilistic Models"
author: "Paulo Fagandini"
institute: "Lisbon Accounting and Business School – Polytechnic University of Lisbon"
format: 
  revealjs:
    theme: default
    logo: images/iscal_logo.svg
    slide-number: true
    cross-ref: true
    incremental: true
    math: 
      method: mathjax
    transition: slide
    footer: "Statistics I"
    from: markdown+emoji
    code-overflow: wrap
    code-block-font-size: 0.75em
    progress: true
editor: source
execute:
  enabled: true
engine: knitr
---

## Disclaimer

These slides are a free translation and adaptation from the slide deck for Estatística I by Prof. Sandra Custódio and Prof. Teresa Ferreira from the Lisbon Accounting and Business School - Polytechnical University of Lisbon.

## Types of random variables

- We studied a couple of ways in which we could categorize the random variables.

- One of these classifications was *discrete* and *continuous* random variables.

- We will start by focusing in the first family of *r.v.s*

## Types of random variables

- According to the type of event we are measuring, we can do even better, and cluster together random variables that behave similarly.

- We will define *families* of **statistical distributions**. Knowing to which statistical distribution our random variable belongs, will endow us with a set of tools to deal with them adequately.

# Bernoulli and Binomial Distributions

## Bernoulli experiment (or trial)

The **Bernoulli experiment** consists in a random experiment with the following features:

* Only two events: $A$ and $A^c$, for example *success* and *failure*. $\Omega=\{A,A^c\}$
* The success happens with probability $p$ and failure with probability $q=1-p$: $$P(A)=p\quad P(A^c)=q=1-p$$

## Bernoulli Process

This process has even further these three characteristics:

* Only two possible outcomes in each draw
* $P(A)$ remains constant thorough the experiment
* Repeated trials are independent, *i.e.* what happened before does not affect what will happen in the future.

. . .

This is process has a binary outcome: Success (1) - Failure (0).

## Bernoulli Distribution

The random variable $X$ follows a Bernoulli distribution with parameter $p \in [0,1]$, $X\sim Ber(1,p)$ if its probability function is given by: $$P(X=x)=f_X(x)=\begin{cases}p^x(1-p)^{1-x} & x\in\{0,1\}\\  0 & otherwise\end{cases}$$

It is trivial to check that $P(X=1)=p$ and $P(X=0)=1-p$.

## Bernoulli Distribution

The first two moments of the distribution (mean and variance) are given by:

* $E[X]=p$
* $V[X]=p(1-p)$

> In summary, Bernoulli's tries to model what is the probability of success or failure in a single independent trial.

# Binomial Distribution

## Binomial Distribution

This distribution, is a **generalization** of Bernoulli's.

In this case, it might be better to start from the summary to stress the difference with Bernoulli's:

> The Binomial distribution answers what is the probability that, after $n$ independent fail-success trials, in any order, for example, you succeeded $m\leq n$ times.

## Binomial Distribution{#binomial_dist}

A random variable $X$ follows a Binomial distribution, $X\sim Bin(n,p)$ if its probability function $P(X=x)$ is:
$$
f_X(x)=\begin{cases}\binom{n}{x}p^x(1-p)^{1-x} & x=0,1,...,n\\ 0 & otherwise\end{cases}
$$

Note that if we change $n$ or $p$ we would get another binomial distribution, i.e. $B(n,p)\neq B(m,r)$ if either $n\neq m$ or $p\neq r$.

Bernoulli is a Binomial distribution with $n=1$.

[Side note about binomials](#app-binomials)

## Binomial distribution

Computing this probability can become very laborious, even for small values for $n$. This can be solved thanks to:

1. Computers and advanced calculators
2. Tables for values for $n$ from 1 to 20, and for $p$ from 0.05 to 0.5. Note that if $p>0.5$ you can just $$X\sim Bin(x,n,p)\ \leftrightarrow\ \hat{X}\sim Bin(n-x,n,1-p)$$

## Binomial distribution

The first two moments of the distribution are found as:

1. $E[X]=\mu_X=\sum x\binom{n}{x}p^x(1-p)^{1-x}=np$
2. $V[X]=E[(X-\mu)^2]=\\=\sum x^2\binom{n}{x}p^x(1-p)^{1-x}-\mu^2=np(1-p)$

## Additivity Theorem of the Binomial Distribution

Let $k$ independent random variables $X_i$ with $i=1,2,..., k$, where $X_i\sim Bin(x_i,n_i,p)$, then

$$
\begin{aligned}
\text{if }S_k&=X_1+X_2+...+X_k=\sum_{i=1}^k X_i \\
S_k&\sim Bin\left(s_k, n=\sum_{i=1}^k n_i, p\right)
\end{aligned}
$$

## Example {#bin-example-1}

Using the [tables](#app-bin-tables) for the binomial distribution, or the calculator, find the value of the following probabilities:

1. $P(X\leq 3)$ if $X\sim Bin(9,0.4)$
2. $P(2\leq X\leq 6)$ if $X\sim Bin(7,0.3)$
3. If $X\sim Bin(10,p)$ and $P(X\leq 5)=0.8338$, what is $p$?

<details>
<summary>✅ Answer</summary>

::: {.nonincremental style="font-size: 0.6em;"}

1. By direct Table inspection $P(X\leq 3)=0.4826$
2. $P(2\leq x\leq 6)=P(x\leq 6)-P(x\leq 2^-)=\\=F(6)-F(1)=0.9998-0.3294=0.6704$
3. By direct inspection of the table $p=0.40$

:::

</details>

## Example {#bin-example-2}

The SNS (Portugal's National Health Service) has said that the probability of an individual carrying a specific gene, that triggers a certain disease is 0.1. In the city of Porto, 10 individuals were randomly selected for a study, while 8 individuals were randomly chosen in Lisbon for the same purpose. Assess the veracity of the following sentence:

::: {.callout}

The probability of, in Lisbon, 2 individuals carrying the gene, knowing that between Porto and Lisbon only 5 individuals were found to carry that gene, is 0.2941.

:::

## Example{.small}

Let $X\sim Bin(10,0.1)$ (for Porto) and $Y\sim Bin(8,0.1)$ (for Lisbon). Then $X+Y\sim Bin(18,0.1)$.

$$
\begin{aligned}
P(Y=2|X+Y=5)&=\frac{P(Y=2, X+Y=5)}{P(X+Y=5)}\\
&=\frac{P(Y=2, X=3)}{P(X+Y=5)}\\
&=\frac{P(Y=2)P(X=3)}{P(X+Y=5)}
\end{aligned}
$$


Using the [tables](#app-bin-tables) we have $P(Y=2)=0.1488$, $P(X=3)=0.0574$, $P(X+Y=5)=0.0218$, and therefore $P(Y=2|X+Y=5)=0.392$. :x: False

# Hypergeometric Distribution

## Hypergeometric Distribution

Suppose you have a population with size $N$, from where $M$ elements have some characteristic, and therefore $N-M$ do not. From that sample, we draw randomly a sample of size $n$, without replacement, and we would like to know, from this sample, how many have the characteristic we mentioned.

::: {.callout}

Given we are not replacing the elements we put in our sample, the events here are not independent!

:::

## Hypergeometric Distribution

In this case the r.v. $X$ would be how many elements from our sample have the referred characteristic. $X\sim Hypergeometric (N,M,n)$ if its probability distribution function $P(X=x)$ is:

$$
f_X(x)=\frac{\binom{M}{x}\binom{N-M}{n-x}}{\binom{N}{n}}
$$

where $max(0,M+n-N)\leq x \leq min(M,n)$

## Hypergeometric Distribution

The first two moments of the distribution are found as:

* $E[X]=\mu_X=n\frac{M}{N}=np$
* $V[X]=npq\frac{N-n}{N-1}$ note here that because we do not replace elements, we get a smaller variance.

## Hypergeometric vs Binomial

::: {.columns}

::: {.column}
* **Binomial**
* Replacement
* Same population every draw
* Independent draws

:::

::: {.column}

* **Hypergeometric**
* No replacement
* Population changes every time
* Dependent draws

:::

:::

## Hypergeometric $\rightarrow$ Binomial

Let $X\sim Hypergeometric(N,M,n)$. If $N>>n$ then the change in the population is very small, and then the draws approximate independent draws (population is very similar after a draw). As a rule of thumb if $\frac{n}{N}\leq 0.1$ or if the sample size is less than 10% of the population, we can approximate the Hypergeometric with the Binomial. 

$$X\sim Hypergeom(N,M,n)\leftrightarrow X\approx Bin\left(n,p=\frac{M}{N}\right)$$

The smaller $\frac{n}{N}$ the better the approximation.

# Geometric Distribution

## Geometric Distribution (Pascal's)

Consider a succession of Bernoulli trials, and let $X$ the r.v. how many trials you need until observing the first success. This is a r.v. because there might be situations when you get success at your first trial, or second, etc. You cannot anticipate this.

$X\sim Geo(p)$ if its probability distribution function $P(X=x)$ is given by:

$$f_X(x)=p^x(1-p)^{1-x}\ ,\ x\in\{1,2,...\},\ p\in[0,1]$$

## Geometric Distribution (Pascal's)

The first two moments of the distribution are found as:

* $E[X]=\mu_X=\frac{1}{p}$
* $V[X]=\frac{1-p}{p^2}$
* $F_X(x)=\begin{cases}0 & x<1 \\ 1-(1-p)^k & k\leq x < k+1,\ k\in\mathbb{N}\end{cases}$

## Geometric Distribution (Pascal's)

There is a special feature of this distribution, it is said it *"lacks memory"* in the following sense. Let $s>t>0$

$$
\begin{aligned}
P(X>s|X>t)&=\frac{P(X>s \wedge X>t)}{P(X>t)}=\frac{P(X>s)}{P(X>t)}\\
&=\frac{1-F(s)}{1-F(t)}=\frac{(1-p)^s}{(1-p)^t}=(1-p)^{s-t}\\
P(X>s-t)&=1-P(x\leq s-t)=1-F(x)\\
&=(1-p)^{s-t}
\end{aligned}
$$

## Geometric and Binomial

| Distribution | r.v. $X$ | Parameter |
| :--: | :--: | :--: |
| Binomial | # Success | # Trials |
| Geometric | # Trials | 1<sup>st</sup> Success |

## Example {#hyper-geom-example}

A company specialized in sport footwear, imports a share of the material that is packed in boxes of 1000 units. To avoid counterfeiting, in each box 5 products are randomly selected, and the whole box is returned if one of these 5 products raises suspicions.

1. What is the probability that a box with 10 suspicious units is returned? [Sol](#app-hyper-example-1)
2. Check if this probability changes too much if you disregard that you are not replacing the items. [Sol](#app-hyper-example-2)
3. What is the probability that we need to inspect 15 units, independently between them, until finding a suspicious item? [Sol](#app-hyper-example-3)
4. How many units you inspect until finding the first suspicious unit? [Sol](#app-hyper-example-4)


# Poisson Distribution

## Poisson Distribution

This distribution is associated with a process of counting, a Poisson process.

Examples:

* Count the number of patients arriving every day to the E.R. in a hospital.
* Count how many calls does a call-center receive in an hour.
* Count how many typos does a book have.

You can count something in a time frame, or a particular region.

## Poisson process

The Poisson process has the following features:

1. It must be homogeneous in time/space. It only depends on the length that you consider to measure, not where, not when.
2. Events happening in disjoint regions/time slots must be independent.
3. The probability of having an event in the exact same space or at the exact same time is negligible (no simultaneous events).

## Poisson Distribution

The r.v. $X$ follows a Poisson distribution if $X\sim Poi(\lambda)$ if its probability distribution function $P(X=x)$ is given by:

$$
f_X(x)=\begin{cases}
\frac{e^{-\lambda}\lambda^x}{x!} & x=0,1,... \\
0 & otherwise
\end{cases}
$$

with $\lambda>0$, which represents the average number of events in a given time slot or region.

## Poisson Distribution

The first two moments of the distribution are found as:

* $E[X]=\lambda$
* $V[X]=\lambda$

## Additivity Theorem of the Poisson Distribution

Let $k$ r.v.s $X_i$ with $i=1,2,...,k$, independent, where $X_i\sim Poi(\lambda_i)$. Let

$$S_k=X_1+...+X_k=\sum_{i=1}^k X_i$$

Then $S_k\sim Poi\left(\Sigma_{i=1}^k\lambda_i\right)$

## Binomial $\rightarrow$ Poisson

Let $X\sim Bin(n,p)$. If $n>>1>>p$, *i.e.* if this is a very rare event (very low success probability) in a very large sample, you can approximate this with a Poisson distribution, where $\lambda=np$.

$X\sim Bin(x,n,p)\leftrightarrow\ X\approx Poi(x,\lambda=np)$

As a rule of thumb, do not approximate if $p\in[0.1,0.9]$ or if $n\leq 20$.

## Example {#poi-example-1}

Find the value of the following probabilities, using the Poisson [table](#app-poi-tables)

1. $P(X\leq 5)$ if $X\sim Poi(10)$ 
2. $P(4\leq X \leq 8)$ if $X\sim Poi(5)$ [Sol](#app-poi-example-2)
3. $P(X=7)$ if $X\sim Poi(10)$ [Sol](#app-poi-example-3)

<details>
<summary>✅ Answer</summary>

::: {.nonincremental style="font-size: 0.6em;"}

1. Looking directly at the table, we find that $P(X\leq 5)=F(5)=0.0671$ 
2. Looking at the table we get $F(8)=0.9319$ and $F(4^-)=F(3)=0.2650$, therefore $P(4\leq X \leq 8)=0.9319-0.2650=0.6669$
3. Looking directly at the table, we see that $P(X\leq 7)=0.2202$ and $P(X\leq 6)=0.1301$, and therefore $P(X=7)=0.2202-0.1301=0.0901$

:::

</details>



## Example {#poi-example-2 style="font-size: 0.8em;"}

The number of patients arriving daily to the ICU in a hospital, follows a [Poisson](#app-poi-tables) process with mean 4. The ICU has capacity of 6 patients, the others, are derived to the nearest hospital. Assess the validity of the following sentences:

1. The probability that, on a given day, there is no need to transfer any patient is 0.8893.[Sol](#app-poi-example-1)
2. The most likely number of patients arriving daily to the ICU is 6.[Sol](#app-poi-example-2)
3. The probability that, on a given day, arrive 5 patients, given that in the previous day only 2 patients arrived, is 0.1563.[Sol](#app-poi-example-3)
4. The probability that, in 5 days, at least 15 patients arrive to the ICU is 0.8435.[Sol](#app-poi-example-4)
5. To ensure that approx. 97% of the time (days) there are no transfers, it is necessary to increase the capacity in 4 more beds.[Sol](#app-poi-example-5)

## Bibliography

<ul>
<li>Murteira, B.; Silva Ribeiro, C.; Andrade e Silva, J. & Pimenta, C.,Introdução à Estatística,Escolar Editora,McGraw-Hill, 2010</li>
<li>Paulino, C. D. & Branco, J. A. (2005). Exercícios de Probabilidade e Estatística. Escolar Editora</li>
<li>Pimenta, F., Andrade e Silva, J.; Silva Ribeiro, C. & Murteira, B., Introdução à Estatística – 3ª Edição, Escolar Editora, 2015</li>
</ul>

# Appendix

## Binomials {#app-binomials}

[Back to Binomial Distribution](#binomial_dist)

## Binomial Table {#app-bin-tables .small}

[Back to exercise](#bin-example-1)

### Distribution Function

<div style="overflow-x: auto; font-size: 0.7em; max-width:100%; max-height:50%">

{{< include _binomial_table.qmd >}}

</div>

## Hypergeometric Example {#app-hyper-example-1}

[Back to the exercise](#hyper-geom-example)

First, note that $X\sim Hypergeometric(1000, 10, n)$

$$
\begin{aligned}
P(X\geq 1)&=1-P(X<1)=1-P(X\leq 0)\\
&=1-P(X=0) = 1-\frac{\binom{10}{0}\binom{990}{5}}{\binom{1000}{5}}\\
&=1-0.9509\approx 0.0491
\end{aligned}
$$

## Hypergeometric Example {#app-hyper-example-2}

[Back to the exercise](#hyper-geom-example)

With reposition we could approximate with the Binomial (note $n/N=0.005<0.1$), $X\approx Bin(n=5,M/N=0.01)$

$$P(X\geq 1)=1-P(X=0)\approx 1-0.95099\approx 0.04901$$

Both values are very close.

## Hypergeometric Example {#app-hyper-example-3}

[Back to the exercise](#hyper-geom-example)

$Y\sim Geo(p=0.01)$,

$$
\begin{aligned}
P(Y=15)&=p(1-p)^{y-1}=0.01(1-0.01)^{14}\\
&=0.01(0.8687458)^14\approx 0.009
\end{aligned}
$$


## Hypergeometric Example {#app-hyper-example-4}

[Back to the exercise](#hyper-geom-example)

$Y\sim Geo(p=0.01)$, then $$E[Y]=\frac{1}{p}=\frac{1}{0.01}=100$$

You need to inspect 100 units on average.

## Poisson Table {#app-poi-tables .small}

[Back to exercise](#poi-example-1)

### Distribution Function

<div style="overflow-x: auto; font-size: 0.7em; max-width:100%; max-height:50%">

{{< include _poisson_table.qmd >}}

</div>

## Poisson Example {#app-poi-example-1}

[Back to the exercise](#poi-example-2)

If $X$ if the r.v. of the number of patients arriving every day at the ICU, $X\sim Poi(4)$. We are interested in $P(X\leq 6)$, looking at the table we get $F(6)=0.8893$. :white_check_mark: True.

## Poisson Example {#app-poi-example-2}

[Back to the exercise](#poi-example-2)

Note that from the table we can see that $P(X=3)=P(X=4)=0.1954$, and also $\lambda=4$. Given that $\lambda=E[X]$, the most likely value must be $\lambda$ or very close. In sum, the sentence is :x: false.


## Poisson Example {#app-poi-example-3}

[Back to the exercise](#poi-example-2)

We need to remember two important facts about the Poisson distribution. In two disjoint periods, the random variables are independent. So the number of patients one day, and the number of patients in the next days are independent. On the other hand, remember that the distribution must be the same for the same time-window (they are independently but identically distributed):

$$P(X_{day2}=5|X_{day1}=2)=P(X_{day2}=5)=0.1563$$

The sentence is :white_check_mark: true.

## Poisson Example {#app-poi-example-4}

[Back to the exercise](#poi-example-2)

Let $Y\sim Poi(20)$ (because of the additivity theorem).

$$
\begin{aligned}
P(Y\geq 15)&=1-P(Y<15)\\
&=1-P(Y\leq 14)=1-F(14)\\&
=1-0.1049=0.8951
\end{aligned}
$$

The sentence is :x: false.

## Poisson Example {#app-poi-example-5}

[Back to the exercise](#poi-example-2)

In this exercise, we need to find, given that $\lambda=4$, the $x$ that makes $F(x)$ greater or equal than 0.97. By inspection in the table, we see that it is $x=8$, but we have know 6 beds, and therefore we would need 2 more beds to satisfy our requirement.

The sentence is :x: false.


