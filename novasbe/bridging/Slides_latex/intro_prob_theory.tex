\documentclass[aspectratio=169]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{opensans}
\usetikzlibrary {decorations.fractals,shadows,shapes.symbols,spy}

\pgfplotsset{compat=1.8,samples=25}

\usetheme{NOVASBE}

\title[]{4509 - Bridging Mathematics}
\subtitle{Introduction to Probability Theory}
\author[P. Fagandini]{Paulo Fagandini}
\institute{}
\date{}

\newtheorem{defenition}{Definition}[section]
\newtheorem{proposition}{Conjecture}[section]
\begin{document}

\colorlet{circle edge}{black!50}
\colorlet{circle area}{black!20}

\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \draw[thick, filled] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        \end{tikzpicture}
        
        \caption{$\Omega:=$ Universe possible outcomes.}
        
   \end{figure}
\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \draw[thick] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        \draw[filled] (-2,0) circle (1.5cm) node [anchor = south east]{$A$};
        
        \end{tikzpicture}
        
        \caption{$A:=$ Event, set of possible outcomes. $A\subseteq \Omega$.}
        
   \end{figure}
\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \draw[thick,filled] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        %\draw (-2,0) circle (1.5cm) node [anchor = south east]{$A$};
        
         \node[draw,circle,fill=white,minimum size=3cm] () at (-3,0) {$A$};
        
        \end{tikzpicture}
        
        \caption{Outcomes not in $A$.}
        
   \end{figure}
\end{frame}

\begin{frame}
   
   So this looks a lot like set theory, and it is. \pause
   
   \vspace{0.5cm}
   
   To know how likely is that an event in $\Omega$ occurs, we need to have a \emph{measure} of $A$. That's why \textbf{measure theory} is so important in probability.\pause
   
   \vspace{0.5cm}
   
   Call the function $P:\mathcal{P}(\Omega)\rightarrow \mathbb{R}$ a measure. For $P$ to be a probability three things must hold:
   \begin{enumerate}
       \item $P(\Omega)=1$.
       \item $P(A\subseteq \Omega)\geq 0$
       \item If, for $A,B\subseteq\Omega$, $A\cap B = \emptyset$ then $P(A\cup B)=P(A)+P(B)$
   \end{enumerate}
   
   These three conditions are known as the \textbf{Kolmogorov Axioms.}\pause
   
   We will not cover measure theory here, just use it in a somehow intuitive way.
   
\end{frame}

\begin{frame}

    \begin{definition}
    Let $(\Omega, \mathcal{P}(\Omega),P)$ be a measure space with $P(\Omega)=1$. Then $(\Omega,\mathcal{P}(\Omega),P)$
 is called a \textbf{probability space} with sample space $\Omega$, event space $\mathcal{P}(\Omega)$, and probability measure $P$.
    \end{definition}
    \begin{proposition}
    
    Let $(\Omega, \mathcal{P}(\Omega), P)$ be a probability space satisfying the Kolmogorov Axioms, then:
    
    \begin{enumerate}
        \item $P(\emptyset)=0$.
        \item If $A\subseteq B$, then $P(A)\leq P(B)$.
        \item $P(A)\in [0,1]$, $\forall A\in\mathcal{P}(\Omega)$.
    \end{enumerate}

    \end{proposition}
    
    
\end{frame}

\begin{frame}

From the example at the start of the class, let's show that $P(A^c)=1-P(A)$.\pause

\begin{enumerate}
    \item $A$ and $A^c$ are disjoint.\pause
    \item $P(A)+P(A^c)=P(A\cup A^c)$.\pause
    \item But $A\cup A^c=\Omega$, so $P(A)+P(A^c)=P(\Omega)$\pause
    \item But we know that $P(\Omega)=1$, so...\pause
    \item $P(A)+P(A^c)=1\quad\Rightarrow \quad P(A^c)=1-P(A)$
\end{enumerate}

\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \draw[thick] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        \draw[filled] (-1,0) circle (1.5cm) node [anchor = south east]{$A$} (1,0) circle (1.5cm) node [anchor = south west]{$B$};
        
        \end{tikzpicture}
        
        \caption{$A\cup B:=$ Outcomes in $A$ or $B$ happening.}
        
   \end{figure}
\end{frame}

\begin{frame}
    What's the probability of $A\cup B$ when $A$ and $B$ are not disjoint? What's the problem with $P(A)+P(B)$?
    
    \pause
    
    \vspace{0.5cm}
    
    $P(A\cap B)$ is being counted twice!, so $$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$ \pause

    \vspace{0.5cm}
    
    What happens with the intersection?

\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \begin{scope}
            \clip (-1,0) circle (1.5cm); 
            \fill[filled] (1,0) circle (1.5cm);
        \end{scope}
    
        \draw[outline] (-1,0) circle (1.5cm) node [anchor = south east]{$A$};
        \draw[outline] (1,0) circle (1.5cm) node [anchor = south west]{$B$};

        \draw[thick] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        %\draw[filled] (-1,0) circle (1.5cm) node [anchor = south east]{$A$} (1,0) circle (1.5cm) node [anchor = south west]{$B$};
        
        \end{tikzpicture}
        
        \caption{$A\cap B:=$ Outcomes that belong in $A$ \underline{and} $B$.}
        
   \end{figure}
\end{frame}

\begin{frame}
    An interesting question, what's the probability that an outcome in $B$ is also an outcome that could happen in $A$?\pause
    
    \vspace{0.2cm}
    
    This is what ``conditional probability'' is all about. Given that we are looking only at elements in $B$, our universe is $B$ and not $\Omega$, so the probability will be $P(A\cap B)$ divided by the size of $B$, that is, $P(B)$.
    
    $$P(A|B)=\frac{P(A\cap B)}{P(B)}$$
\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \begin{scope}
            \clip (-1,0) circle (1.5cm); 
            \fill[filled] (1,0) circle (1.5cm);
        \end{scope}
    
        \draw[outline] (-1,0) circle (1.5cm) node [anchor = south east]{$A$};
        \draw[outline] (1,0) circle (1.5cm) node [anchor = south west]{$B$};

        \draw[thick] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        \end{tikzpicture}
        
        \caption{$A\cap B:=$ Outcomes that belong in $A$ \underline{and} $B$.}
        
   \end{figure}
\end{frame}

\begin{frame}
   \begin{figure}
       \centering
       \begin{tikzpicture}

        \begin{scope}
            \clip (-1,0) circle (1.5cm); 
            \fill[filled] (1,0) circle (1.5cm);
        \end{scope}
    
        \draw[outline, opacity = 0.15] (-1,0) circle (1.5cm) node [anchor = south east]{$A$};
        \draw[outline] (1,0) circle (1.5cm) node [anchor = south west]{$B$};

        \draw[thick, opacity = 0.15] (-5,-3)--(5,-3)--(5,3)--(-5,3) node[anchor = north west] {$\Omega$}--(-5,-3);
        
        \end{tikzpicture}
        
        \caption{$A | B $, Outcomes that belong to $A$ given that they are also in $B$.}
        
   \end{figure}
\end{frame}

\begin{frame}
    Note that as $A\cap B\subseteq B$, then $P(A\cap B)\leq P(B)$, and therefore $P(A|B)\leq 1$.
    
    \vspace{1cm}
    
     It should be clear also that $P(A|B)=P(B|A)$ if and only if $P(A)=P(B)$.
\end{frame}

\begin{frame}
    Note that if we know $P(A|B)$ then we can obtain $P(A\cap B)$ $$P(A|B)=\frac{P(A\cap B)}{P(B)}\Leftrightarrow P(A\cap B)=P(B)P(A|B)$$ This is known as the \textbf{product rule}.
\end{frame}

\begin{frame}
    Assume now that $B=C\cap D$. Then we have $P(A\cap(C\cap D))=P(C\cap D)P(A|(C\cap D))$, but $P(C\cap D)=P(D)P(C|D)$, so we have $$P(A\cap C\cap D)=P(D)P(C|D)P(A|C\cap D)$$ that can be generalized as follows,
    
    \begin{align*}
        P\left(\bigcap_{i=1}^k A_i\right)= P(A_1)\prod_{i=2}^k P\left(A_i\left|\bigcap_{j=1}^{i-1} A_j\right.\right)
    \end{align*}
\end{frame}

\begin{frame}
    Assume I throw randomly a ball into a box, but you cannot see it:
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \node [rectangle, left color=red, right color=red!100!white, anchor=north, minimum width=5cm, minimum height=5cm] (box) at (current page.north){};
        \end{tikzpicture}
    \end{figure}
    
    (it's there)...
\end{frame}

\begin{frame}
    Now I tell you, I throw randomly another ball, but you cannot see it either.
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \node [rectangle, left color=red, right color=red!50!white, anchor=north, minimum width=5cm, minimum height=5cm] (box) at (current page.north){};
        \end{tikzpicture}
    \end{figure}
    
    However, I tell you (I can see them), this second ball is to the right of the initial ball. 
\end{frame}

\begin{frame}
    Again, I tell you, I throw randomly another ball, and tell you that it is to the right of the initial ball..
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \node [rectangle, left color=red, right color=red!30!white, anchor=north, minimum width=5cm, minimum height=5cm] (box) at (current page.north){};
        \end{tikzpicture}
    \end{figure}
    
     
\end{frame}

\begin{frame}
    Again, I tell you, I throw randomly another ball, and tell you that it is to the right of the initial ball..
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \node [rectangle, left color=red, right color=white, anchor=north, minimum width=5cm, minimum height=5cm] (box) at (current page.north){};
        \end{tikzpicture}
    \end{figure}
    
     
\end{frame}

\begin{frame}
    
    If this happens many times, with the updated information, you will believe that the ball is to left with more and more confidence.
    \vspace{0.3cm}
    
    This is Bayesian updating, with the new data, you update your beliefs about something, and actually this was similar to Bayes experiment to reach this conclusion.
    
\end{frame}

\begin{frame}
    So the question is:
    \begin{enumerate}
        \item Where is the ball?
        \item Where is the ball given the 1 ball randomly fell to its right?
        \item Where is the ball given that 2 balls randomly (and indep) fell to its right?
        \item Where is the ball given that 3 balls randomly (and indep) fell to its right?
        \item ...
    \end{enumerate}
\end{frame}

\begin{frame}
\textbf{Baye's rule}:
    \begin{align*}
        P(A|B)=\frac{P(B|A)P(A)}{P(B)}
    \end{align*}
    \begin{example}
    Assume a car shows the warning signal (Event $B$) which indicates that it might have a problem (Event $A$). $P(A|B)$ is the probability that the car has a problem given that the light turned on. $P(B|A)$ displays the probability that the car turns the light on when there is a problem, $P(A)$ is the unconditional probability that the car has a problem and $P(B)$ is the unconditional probability that the warning light turns on.
    \end{example}
\end{frame}

\begin{frame}{Random Variables}
    \begin{definition}
        A \textbf{random variable} is a measurable function $X:\Omega\rightarrow \mathbb{X}$, where $\mathbb{X}$ is a measurable space, such that for $S\subseteq\mathbb{X}$
        \begin{align*}
            Pr(X\in S)=P(\{\omega\in\Omega | X(\omega)\in S\})
        \end{align*}
    \end{definition}
    \vspace{0.5cm}
    So the probability that $X$ belongs to $S$ is the measure of the set of outcomes that make $X$ to have some particular characteristic (that makes it belong to $S$).
\end{frame}

\begin{frame}
    $S$ could be $\mathbb{R}^n$, true/false, $\mathbb{N}$, a color, a decease, etc.\pause
    
    \vspace{0.5cm}
    
    \begin{definition}
        Let $X:\Omega\rightarrow\mathbb{X}$ be a r.v. $X$ is said to be \textbf{discrete} if $\mathbb{X}$ is finite or countable infinite, and \textbf{continuous} if $\mathbb{X}$ is uncountable.
    \end{definition}
    
    \vspace{0.5cm}
    
    The true question is, how likely is that $X$ belongs to $S$? (how likely is that $x=2$, $x=true$, $x=yellow$, etc.?)
\end{frame}

\begin{frame}
    \begin{definition}
        Let $X:\Omega\rightarrow\mathbb{X}$ be a r.v. The function $f_X:\mathbb{X}\rightarrow\mathbb{R}$ is the \textbf{density} of $X$ if it holds that:
        \vspace{0.3cm}

        \begin{itemize}
            \item for any $x\in\mathbb{X}$, $f_X(x)=P(\{\omega|X(\omega)=x\})$ when $X$ is a discrete r.v., and
            \vspace{0.3cm}
            \item for any $E\subseteq \mathbb{X}$, $\int_E f_X(x)dx=P(\{\omega|X(\omega)\in E\})$ when $X$ is a continuous r.v.
        \end{itemize}
        
    \end{definition}
    
    Note that it also must hold that $\int_\mathbb{X} f(x)dx=1$.
\end{frame}

\begin{frame}
    \begin{definition}
    Let the continuous r.v. $X:\Omega\rightarrow \mathbb{X}$, where $\mathbb{X}\subseteq\mathbb{R}$. The \textbf{cumulative} function is:
    
    $$F(x) = Pr(X\leq x) = \int_{\mathbb{X}\cap(-\infty,x]}f_X(z)dz$$
    \end{definition}
\end{frame}

\begin{frame}
    \begin{definition}
        The \textbf{expected value} of a continuous r.v. $X:\Omega\rightarrow\mathbb{X}$ is defined as:
        
        \begin{align*}
            E[X]=\int_{\mathbb{X}}xf_X(x)dx
        \end{align*}
    \end{definition}
    
    Note:
    \begin{enumerate}
        \item This is often found as $E[x]=\mu_X$.
        \item If $g(x)$ is a function, then $E[g(x)]=\int_\mathbb{X} g(x)f(x)dx$ is the expected value of the function.
    \end{enumerate}
\end{frame}

\begin{frame}
    \begin{definition}
        The \textbf{variance} of a continuous r.v. $X:\Omega\rightarrow\mathbb{X}$ is defined as:
        
        \begin{align*}
            var(X)=E[(X-E[x])^2]=\int_{\mathbb{X}}(x-E[X])^2f_X(x)dx
        \end{align*}
    \end{definition}
    
    You can often find this as $var(X)=\sigma_X^2$.
\end{frame}

\begin{frame}
 \begin{definition}
    A continuous r.v. $X:\Omega\rightarrow\mathbb{R}$ is said to be \textbf{Normal} or \textbf{Gaussian} if its density is:
    \begin{align*}
        f_X(x)= \frac{\exp({-\frac{(x-\mu_X)^2}{2\sigma_X^2}})}{\sqrt{2\pi\sigma_X^2}}
    \end{align*}
 \end{definition}
 
    \begin{definition}
        If $X$ is Normal, and satisfies that $\mu_X=0$ and $\sigma^2=1$ it is called \textbf{Standard Normal}. 
    \end{definition}
\end{frame}

\begin{frame}

    \begin{definition}
    The \textbf{conditional density} $f_{X|B}$ of a continuous r.v. $X$, given an event $B$, with $P(B)>0$ must satisfy that:
    \begin{align*}
        P(X\in A|B)=\int_{A}f_{X|B}(x)dx
    \end{align*}
    \end{definition}
    
    Note: To find, for example, the conditional expectation, you should compute the expectation as usual but using this density instead.
\end{frame}

\begin{frame}
\begin{definition}
    Let $X:\Omega\rightarrow\mathbb{X}$ and $Y:\Omega\rightarrow\mathbb{Y}$ be two jointly continuous r.v. The \textbf{joint density} $f_{XY}:\mathbb{X}\times\mathbb{Y}\rightarrow\mathbb{R}$ is a function such that:

    $$\int_E\int_I f_{X,Y}(x,y)dxdy=Pr(\{\omega\in\Omega|X(\omega)\in E,Y(\omega)\in I\}) $$ for any $E\subseteq\mathbb{X}$, $I\subseteq\mathbb{Y}$.

\end{definition}

\underline{Note:} If $g(x,y)$ is a function, then $$E[g(x,y)]=\int_E\int_I g(x,y)f_{X,Y}(x,y)dxdy$$
\end{frame}

\begin{frame}
    \begin{definition}
        Let the continuous r.v. $X$ and $Y$ have a joint density $f_{X,Y}:\mathbb{X}\times\mathbb{Y}\rightarrow\mathbb{R}$. The \textbf{marginal} density is the function $f_X(x):\mathbb{X}\rightarrow\mathbb{R}$ such that
        
        $$f_X(x)=\int_{\mathbb{Y}}f_{XY}(x,y)dy$$
        
    \end{definition}
    
    \vspace{0.2cm}
    
    What this is trying to do, is to isolate the effect of $x$.
\end{frame}

\begin{frame}
    \begin{definition}
        The \textbf{conditional density} of $X$, given $Y=y$, is a function $f_{X|Y}(x,y)$ such that
        \vspace{0.2cm}
 $f_{X|Y}(x,y)=P(\{\omega\in\Omega|X(\omega)=x\}|\{\omega\in\Omega|Y(\omega)=y\})$
        or,
        \begin{align*}
            f_{X|Y}(x,y)=\frac{f_{X,Y}(x,y)}{f_Y(y)}
        \end{align*}
    \end{definition}
    Again, if you want to find conditional expectation you should use this density function.
\end{frame}

\begin{frame}
    \begin{definition}
        Two continuous r.v. $X$ and $Y$ are \textbf{independent} if their joint density  is:
        \begin{align*}
            f_{X,Y}(x,y)=f_X(x)f_Y(y),\quad \forall x,y
        \end{align*}
        \end{definition}
        \vspace{0.2cm}
    Note that as a consequence of independence, for all $x,y$
    \begin{align*}
        f_{X,Y}(x|y)=f_X(x)\quad f_Y(y)>0\\
        f_{X,Y}(y|x)=f_Y(y)\quad f_X(x)>0
    \end{align*}
    And, also for two functions $g$ and $h$
    \begin{align*}
        E[g(x)h(Y)]=E[g(X)]E[h(Y)]
    \end{align*}
    Finally $var(X+Y)=var(X)+var(Y)$.
    
\end{frame}

\begin{frame}
    \begin{definition}
        The \textbf{covariance} of two r.v., denoted as $cov(X,Y)$, is defined by:
        $$cov(X,Y)=E[(X-E[X])(Y-E[Y])]$$
        If $cov(X,Y)=0$, $X$ and $Y$ are said to be uncorrelated.
    \end{definition}
    \begin{definition}
        The \textbf{correlation coefficient} $\rho$ of two r.v. $X$ and $Y$ that have strictly positive variances is defined as:
        \begin{align*}
            \rho=\frac{cov(X,Y)}{\sqrt{var(X)var(Y)}}
        \end{align*}
    \end{definition}
\end{frame}

\end{document}
